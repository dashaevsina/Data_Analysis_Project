---
title: "Data Analysis Project code"
subtitle: "UN data clustering analysis"
output: html_notebook 
---

# Libraries
Load necessary libraries.

```{r}
library(pdftools)
library(tidyverse)

library(tm)

library(ggplot2)
library(lsa)

library(wordcloud)

library(magrittr)
library(dplyr)
library(ggpubr)

library(proxy)
```


# Create a vector
Create a vector data structure in R of the UN PDF file names using the `list.files` function. 
```{r}
all_files <- list.files(pattern = "pdf$")
all_files 

typeof(all_files)
```

In the `pdftools` library, the function pdf_text is used to extract text. Using the `lapply` function, the pdf_text function can be applied to each element in the “all_files” vector to then create an object called “UN_files”.
```{r}
UN_files <- lapply(all_files, pdf_text)
```

This creates a list object with a specific number of elements, one for each document. The `length` function verifies it contains xyz elements:
```{r}
length(UN_files)
```

Thus, each element is a vector that contains the text of the PDF file. The length of each vector corresponds to the number of pages in the PDF file. For example, the first vector has length xyz because the first PDF file has xyz pages. The `length` function can be applied to each element to see this:
```{r}
lapply(UN_files, length) 
```



# Textmining

Load the `tm package` and then create a corpus, which is essentially a database for the UN texts. 
```{r}
UN_corpus <- Corpus(URISource(all_files),
               readerControl = list(reader = readPDF))
```

## Term-document matrix
Having created a corpus called `UN_corpus`, a term-document matrix (TDM) can be generated, which stores counts of terms for each document. First, the punctuation marks have to be removed. 
```{r}
UN_corpus <- tm_map(UN_corpus, removePunctuation, ucp = TRUE)
```

The `tm package` includes a function to create a TDM called `TermDocumentMatrix`. NB: no stemming is applied.
```{r}
UN_corpus.tdm <- TermDocumentMatrix(UN_corpus, 
                                   control = 
                                     list(stopwords = TRUE,
                                          tolower = TRUE,
                                          stemming = TRUE,
                                          removeNumbers = TRUE,
                                          bounds = list(global = c(3, Inf))))
```

Inspect the UN_corpus term-document matrix:
```{r}
inspect(UN_corpus.tdm[1:10,]) 
```

### Summary statistics
There are a few functions for summary statistics in the `tm package`. For instance, the `findFreqTerms` function can find frequently occurring terms. Words that occur at least 100 times are shown here:
```{r}
findFreqTerms(UN_corpus.tdm, lowfreq = 100, highfreq = Inf)
```

The counts of these words can be shown in each of the UN report PDF documents:
```{r}
frequent_terms <- findFreqTerms(UN_corpus.tdm, lowfreq = 100, highfreq = Inf)
as.matrix(UN_corpus.tdm[frequent_terms,]) 
```

The total counts for the most frequent words can be saved into a matrix. The  sum function is subsequently applied across the rows:

```{r}
frequent_terms.tdm <- as.matrix(UN_corpus.tdm[frequent_terms,])
sort(apply(frequent_terms.tdm, 1, sum), decreasing = TRUE)
```

# Document-term matrix
NB: In a document-term matrix, rows represent documents in the collection and columns represent terms, whereas the term-document matrix is the transpose of DTM.
Create document-term matrix:
```{r}

UN_corpus <- tm_map(UN_corpus, removePunctuation, ucp = TRUE)

dtm = DocumentTermMatrix(UN_corpus,
                         control = list(
                                        stopwords = TRUE,
                                        tolower = TRUE,
                                        removeNumbers = TRUE,
                                        stemming = TRUE,
                                        bounds = list(global = c(3, Inf))))

dtm <- dtm[, names(head(sort(colSums(as.matrix(dtm))), 400))]
dtm <- dtm[, names(sort(colSums(as.matrix(dtm))))]

inspect(dtm)
```


## TF-IDF
Term frequency-inverse document frequency (TF-IDF):
```{r}
UN_dtm <- weightTfIdf(dtm, normalize = TRUE)
dtm.matrix = as.matrix(UN_dtm)

inspect(UN_dtm)
```



# Calculating Distance
The clustering algorithm uses distances to cluster documents.

## Eucledian distance
Use the `dist` function (for matrix distance/ similarity computation) to calculate the euclidean distance between the documents.
```{r}
UN_dtm <- as.matrix(UN_dtm)
distMatrix_Eucledian <- dist(UN_dtm, method="euclidean")
print(distMatrix_Eucledian)
```

## Cosine distance
Calculate cosine distance:
```{r}
UN_tdm <- as.matrix(UN_corpus.tdm)
cosine_dist_mat <- as.matrix(dist(t(UN_tdm), method = "cosine"))

cosine_dist_mat
```

The diagonal of the cosine distance matrix `cosine_dist_mat` should be removed, since the distance between a document and itself is neither informative, nor necessary.
```{r}
diag(cosine_dist_mat) <- NA
cosine_dist <- apply(cosine_dist_mat, 2, mean, na.rm=TRUE)

cosine_dist
```

# Clustering
The R algorithm `hclust` will be used for agglomerative (bottom-up) hierarchical clustering based on Eucledian distance. Hierarchical clustering is computationally inexpensive, as opposed to k-means clustering.
Ward's method is used as the merge rule. Other methods, such as "ward.D2", "single", "complete", "average", "mcquitty", "median", or "centroid" can likewise be used.

The tree can be cut into clusters. These can be determined either arbitrarily  or based on one of three methods (the Elbow method, Average silhouette method or Gap statistic method). 
```{r}
groups_hierarchical <- hclust(distMatrix_Eucledian, method="ward.D")
clustering <- cutree(groups_hierarchical, 10)
plot(groups_hierarchical, 
     main="Hierarchical clustering of UN data",
       cex=0.9, hang=-1)
rect.hclust(groups_hierarchical, 10, border="mediumseagreen")
```

# Multidimensional scaling (MDS)
In data analysis, multidimensional scaling is a visual representation of information contained in a distance matrix that reflects the distances or dissimilarities between sets of objects.
```{r}
# Compute MDS
mds <- UN_tdm %>%
  dist() %>%          
  cmdscale() %>%
  as_tibble()
colnames(mds) <- c("Coordinate_1", "Coordinate_2") # unique column names!
```

An MDS plot arranges the points on the graph so that the distances among each pair of points correlates as accurately as possible to the dissimilarity between those two samples.
```{r}
# Plot MDS
ggscatter(mds, x = "Coordinate_1", y = "Coordinate_2", 
          label = rownames(UN_corpus.tdm),
          size = 1,
          repel = TRUE)
```


